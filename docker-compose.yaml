version: '3.8'
services:
  ngrok:
    image: ngrok/ngrok:latest
    ports:
      - 4040:4040
    mem_limit: 25g
    command:
      - "start"
      - "--all"
      - "--config"
      - "/etc/ngrok.yml"
    volumes:
      - ./ngrok/ngrok.yml:/etc/ngrok.yml
    depends_on:
      - webui
      - nginx

  ollama:
    image: ollama/ollama
    mem_limit: 25g
    volumes:
      - "${ROOT}/.ollama/models:/root/.ollama/models"
    ports:
      - "11434:11434"

  webui:
    image: ghcr.io/open-webui/open-webui:main
    mem_limit: 25g
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_API_BASE_URL=http://localhost:11434/api
    volumes:
      - webui_data:/app/backend/data
    depends_on:
      - ollama

  nginx:
    image: nginx
    mem_limit: 25g
    ports:
    - "80:80"
    volumes:
    - ./nginx-conf/nginx.conf:/etc/nginx/nginx.conf:ro

volumes:
  webui_data:
